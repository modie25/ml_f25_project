{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d00a793-1ae8-47e9-89f9-8052b23110af",
   "metadata": {},
   "source": [
    "## A.3 Random Forest Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168dd7b6-3a66-4942-9f33-65c262fe17bd",
   "metadata": {},
   "source": [
    "### A.3.1 Supplemental Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40047109-14a0-4a27-8ef9-439c354c2eda",
   "metadata": {},
   "source": [
    "#### Gini Impurity Calculation\n",
    "Gini impurity measures how mixed the classes are within a node. It is computed as:\n",
    "\n",
    "$$\n",
    "\\text{Gini impurity}(S) = 1 - \\sum_{i=1}^{k} p_i^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $S$ = collection of features\n",
    "- $p_i$ = proportion of samples belonging to class \\( i \\)  \n",
    "- $k$ = total number of classes  \n",
    "\n",
    "A Gini value of 0 indicates a perfectly pure node (all samples belong to one class), while higher values indicate more class mixing.\n",
    "\n",
    "#### Information Gain (Split Criterion)\n",
    "\n",
    "Decision trees choose the split that produces the largest reduction in impurity.  \n",
    "Information gain is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Gain}(S, A) = \\text{Impurity}(S) - \\sum_{v\\in Value(A)} \n",
    "\\frac{|S_v|}{|S|} \\text{Impurity}(S_v)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $S$ is a collection of features\n",
    "- $A$ is a feature in $S$\n",
    "- Value(A) is the set of all possible values for attribute A\n",
    "- $S_v$ is the subset of $S$ for which attribute A has value $v$. \n",
    "\n",
    "The split with the highest information gain is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b227529-1ecf-4926-a7cd-9ee0b3b9639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5ac01f-7d86-4da0-8274-68c9881b7b51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/processed/winequality-red-normalized-train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/processed/winequality-red-normalized-test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     },\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/processed/winequality-red-pca-train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/processed/winequality-red-pca-test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     },\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmote\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/processed/winequality-red-oversampling-train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/processed/winequality-red-normalized-test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# correct pairing?\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     }\n\u001b[1;32m     14\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"normalized\": {\n",
    "        \"train\": pd.read_csv(\"../../data/processed/winequality-red-normalized-train.csv\"),\n",
    "        \"test\": pd.read_csv(\"../../data/processed/winequality-red-normalized-test.csv\")\n",
    "    },\n",
    "    \"pca\": {\n",
    "        \"train\": pd.read_csv(\"../../data/processed/winequality-red-pca-train.csv\"),\n",
    "        \"test\": pd.read_csv(\"../../data/processed/winequality-red-pca-test.csv\")\n",
    "    },\n",
    "    \"smote\": {\n",
    "        \"train\": pd.read_csv(\"../../data/processed/winequality-red-oversampling-train.csv\"),\n",
    "        \"test\": pd.read_csv(\"../../data/processed/winequality-red-normalized-test.csv\")  # correct pairing?\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b4e02-f506-48c6-a440-f21843ae1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150, 200],\n",
    "    \"max_depth\": [None, 15, 25, 50],\n",
    "    \"max_features\": ['sqrt', 'log2', None],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c8c75-58e6-446d-b2c1-621b920a9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table = []\n",
    "\n",
    "for name, dset in datasets.items():\n",
    "    print(f\"\\n{name} dataset\")\n",
    "\n",
    "    train_df = dset[\"train\"]\n",
    "    test_df = dset[\"test\"]\n",
    "\n",
    "    # split into X and y\n",
    "    X_train = train_df.drop(columns=[\"quality\"])\n",
    "    y_train = train_df[\"quality\"]\n",
    "    X_test = test_df.drop(columns=[\"quality\"])\n",
    "    y_test = test_df[\"quality\"]\n",
    "\n",
    "    # grid search\n",
    "    grid = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_grid,\n",
    "        scoring=\"f1_macro\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_idx = grid.best_index_\n",
    "    best_params = grid.best_params_\n",
    "\n",
    "    # CV metrics\n",
    "    train_cv_macro_f1_mean = grid.cv_results_[\"mean_train_score\"][best_idx]\n",
    "    train_cv_macro_f1_std  = grid.cv_results_[\"std_train_score\"][best_idx]\n",
    "    val_cv_macro_f1_mean   = grid.best_score_\n",
    "    val_cv_macro_f1_std    = grid.cv_results_[\"std_test_score\"][best_idx]\n",
    "\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(f\"CV Macro F1 (mean): {val_cv_macro_f1_mean:.4f}\")\n",
    "    print(f\"CV Macro F1 (std):  {val_cv_macro_f1_std:.4f}\")\n",
    "\n",
    "    # train model on full training data\n",
    "    best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # predict on test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # test metrics\n",
    "    test_macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test Macro F1: {test_macro_f1:.4f}\\n\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, normalize=\"true\")\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=sorted(y_train.unique()))\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\")\n",
    "    plt.title(f\"Normalized Confusion Matrix - {name.upper()} dataset\")\n",
    "    plt.show()\n",
    "\n",
    "    # store results\n",
    "    results_table.append({\n",
    "        \"Dataset\": name,\n",
    "        \"Train CV Macro F1 (mean)\": round(train_cv_macro_f1_mean, 4),\n",
    "        \"Train CV Macro F1 (std)\": round(train_cv_macro_f1_std, 4),\n",
    "        \"Test Macro F1\": round(test_macro_f1, 4),\n",
    "        \"Val CV Macro F1 (mean)\": round(val_cv_macro_f1_mean, 4),\n",
    "        \"Val CV Macro F1 (std)\": round(val_cv_macro_f1_std, 4),\n",
    "        \"Test Accuracy\": round(test_acc, 4)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215aad7d-f1ea-461c-ae3a-0987159bbca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87652192-14de-4dc2-b5e2-66d921165882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_norm.drop(columns=[\"quality\"])\n",
    "y = df_norm[\"quality\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# best hyperparameters from GridSearch besides class_weight\n",
    "best_params_fixed = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": None,\n",
    "    \"max_features\": None,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for cw in [None, \"balanced\"]:\n",
    "    print(f\"\\nUsing class_weight = {cw}\")\n",
    "    \n",
    "    model = RandomForestClassifier(class_weight=cw, **best_params_fixed)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77f452-2604-417d-8ebb-06bbc2a6c9e5",
   "metadata": {},
   "source": [
    "Without the class_weight parameter, the model achieves an accuracy of 0.67 and macro F1 of 0.389, indicating problems with performance in smaller classes. Introducing class weights improves macro F1 to 0.4132, indicating increase in performance on smaller classes (particularly quality = 8). This also did not sacrifice performance on the bigger classes, and improved accuracy overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15493b99-20e0-4b36-9956-ece6f7d189f8",
   "metadata": {},
   "source": [
    "### A.3.2 Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c954efe-b3c8-4d5e-ac86-f8387b9f6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score, classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline as SkPipeline\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3a69f-685c-48d3-af6c-70956a344bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "raw_path = \"../../data/raw/winequality-red.csv\"\n",
    "\n",
    "with open(raw_path, \"r\") as f:\n",
    "    header_line = f.readline().strip()\n",
    "\n",
    "header_clean = header_line.replace('\"\"', '\"').replace('\"', '')\n",
    "columns = [col.strip() for col in header_clean.split(';')]\n",
    "\n",
    "df_raw = pd.read_csv(raw_path, sep=\";\", skiprows=1, names=columns)\n",
    "\n",
    "X = df_raw.drop(columns=[\"quality\"])\n",
    "y = df_raw[\"quality\"]\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc967e8b-4892-486b-86c1-d3d547d28f75",
   "metadata": {},
   "source": [
    "#### A.3.2.1 Normalized Pipeline & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908dccf5-2b42-423b-972f-b2210e24b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_normalized = SkPipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"rf\", RandomForestClassifier(random_state=42)),\n",
    "])\n",
    "\n",
    "param_grid_normalized = {\n",
    "    \"rf__n_estimators\": [50, 100, 150, 200],\n",
    "    \"rf__max_depth\": [None, 15, 25, 50],\n",
    "    \"rf__max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"rf__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "grid_norm = GridSearchCV(\n",
    "    pipe_normalized,\n",
    "    param_grid=param_grid_normalized,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "print(\"Running normalized pipeline\")\n",
    "grid_norm.fit(X_train, y_train)\n",
    "\n",
    "best_idx = grid_norm.best_index_\n",
    "best_params = grid_norm.best_params_\n",
    "\n",
    "# cv metrics\n",
    "train_cv_macro_f1_mean = grid_norm.cv_results_[\"mean_train_score\"][best_idx]\n",
    "train_cv_macro_f1_std  = grid_norm.cv_results_[\"std_train_score\"][best_idx]\n",
    "\n",
    "val_cv_macro_f1_mean = grid_norm.best_score_\n",
    "val_cv_macro_f1_std  = grid_norm.cv_results_[\"std_test_score\"][best_idx]\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(f\"Train CV Macro F1 (mean): {train_cv_macro_f1_mean:.4f}\")\n",
    "print(f\"Train CV Macro F1 (std):  {train_cv_macro_f1_std:.4f}\")\n",
    "print(f\"Val   CV Macro F1 (mean): {val_cv_macro_f1_mean:.4f}\")\n",
    "print(f\"Val   CV Macro F1 (std):  {val_cv_macro_f1_std:.4f}\")\n",
    "\n",
    "# test metrics\n",
    "best_norm = grid_norm.best_estimator_\n",
    "y_pred_norm = best_norm.predict(X_test)\n",
    "\n",
    "test_macro_f1 = f1_score(y_test, y_pred_norm, average=\"macro\")\n",
    "test_acc = accuracy_score(y_test, y_pred_norm)\n",
    "\n",
    "print(f\"\\nTest Macro F1: {test_macro_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_norm, zero_division=0))\n",
    "\n",
    "# confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred_norm, normalize=\"true\", values_format=\".2f\"\n",
    ")\n",
    "plt.title(\"Normalized Data – RF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab08c8-2b7a-4d7c-8584-45ebbe65dff1",
   "metadata": {},
   "source": [
    "#### A.3.2.2 PCA Pipeline & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06efc74a-ada6-4015-8532-9b9ac71e3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_pca = SkPipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=5)),\n",
    "    (\"rf\", RandomForestClassifier(random_state=42)),\n",
    "])\n",
    "\n",
    "param_grid_pca = {\n",
    "    \"rf__n_estimators\": [50, 100, 150, 200],\n",
    "    \"rf__max_depth\": [None, 15, 25, 50],\n",
    "    \"rf__max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"rf__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "grid_pca = GridSearchCV(\n",
    "    pipe_pca,\n",
    "    param_grid=param_grid_pca,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "print(\"Running PCA pipeline\")\n",
    "grid_pca.fit(X_train, y_train)\n",
    "\n",
    "best_idx = grid_pca.best_index_\n",
    "best_params_pca = grid_pca.best_params_\n",
    "\n",
    "# cv metrics\n",
    "train_cv_macro_f1_mean = grid_pca.cv_results_[\"mean_train_score\"][best_idx]\n",
    "train_cv_macro_f1_std  = grid_pca.cv_results_[\"std_train_score\"][best_idx]\n",
    "val_cv_macro_f1_mean   = grid_pca.best_score_\n",
    "val_cv_macro_f1_std    = grid_pca.cv_results_[\"std_test_score\"][best_idx]\n",
    "\n",
    "print(\"Best parameters:\", best_params_pca)\n",
    "print(f\"Train CV Macro F1 (mean): {train_cv_macro_f1_mean:.4f}\")\n",
    "print(f\"Train CV Macro F1 (std):  {train_cv_macro_f1_std:.4f}\")\n",
    "print(f\"Val   CV Macro F1 (mean): {val_cv_macro_f1_mean:.4f}\")\n",
    "print(f\"Val   CV Macro F1 (std):  {val_cv_macro_f1_std:.4f}\")\n",
    "\n",
    "# test metrics\n",
    "best_pca = grid_pca.best_estimator_\n",
    "y_pred_pca = best_pca.predict(X_test)\n",
    "\n",
    "test_macro_f1_pca = f1_score(y_test, y_pred_pca, average=\"macro\")\n",
    "test_acc_pca = accuracy_score(y_test, y_pred_pca)\n",
    "\n",
    "print(f\"\\nTest Macro F1: {test_macro_f1_pca:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_pca:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_pca, zero_division=0))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred_pca, normalize=\"true\", values_format=\".2f\"\n",
    ")\n",
    "plt.title(\"PCA (5 components) – RF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b5cc4-fc0f-4ed7-9b16-c84902ebc248",
   "metadata": {},
   "source": [
    "#### A.3.2.3 SMOTE Pipeline & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a3016-4403-44d2-b348-f524745947ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_smote = ImbPipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"smote\", SMOTE(random_state=42, k_neighbors=3)),\n",
    "    (\"rf\", RandomForestClassifier(random_state=42)),\n",
    "])\n",
    "\n",
    "param_grid_smote = {\n",
    "    \"rf__n_estimators\": [50, 100, 150, 200],\n",
    "    \"rf__max_depth\": [None, 15, 25, 50],\n",
    "    \"rf__max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"rf__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "grid_smote = GridSearchCV(\n",
    "    pipe_smote,\n",
    "    param_grid=param_grid_smote,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "print(\"Running SMOTE pipeline\")\n",
    "grid_smote.fit(X_train, y_train)\n",
    "\n",
    "best_idx_smote = grid_smote.best_index_\n",
    "best_params_smote = grid_smote.best_params_\n",
    "\n",
    "# cv metrics\n",
    "train_cv_macro_f1_mean_sm = grid_smote.cv_results_[\"mean_train_score\"][best_idx_smote]\n",
    "train_cv_macro_f1_std_sm  = grid_smote.cv_results_[\"std_train_score\"][best_idx_smote]\n",
    "val_cv_macro_f1_mean_sm   = grid_smote.best_score_\n",
    "val_cv_macro_f1_std_sm    = grid_smote.cv_results_[\"std_test_score\"][best_idx_smote]\n",
    "\n",
    "print(\"Best parameters:\", best_params_smote)\n",
    "print(f\"Train CV Macro F1 (mean): {train_cv_macro_f1_mean_sm:.4f}\")\n",
    "print(f\"Train CV Macro F1 (std):  {train_cv_macro_f1_std_sm:.4f}\")\n",
    "print(f\"Val   CV Macro F1 (mean): {val_cv_macro_f1_mean_sm:.4f}\")\n",
    "print(f\"Val   CV Macro F1 (std):  {val_cv_macro_f1_std_sm:.4f}\")\n",
    "\n",
    "# test metrics\n",
    "best_smote = grid_smote.best_estimator_\n",
    "y_pred_smote = best_smote.predict(X_test)\n",
    "\n",
    "test_macro_f1_smote = f1_score(y_test, y_pred_smote, average=\"macro\")\n",
    "test_acc_smote = accuracy_score(y_test, y_pred_smote)\n",
    "\n",
    "print(f\"\\nTest Macro F1: {test_macro_f1_smote:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc_smote:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_smote, zero_division=0))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred_smote, normalize=\"true\", values_format=\".2f\"\n",
    ")\n",
    "plt.title(\"SMOTE – RF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37098aae-4d96-443e-abe0-968d4313c2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
