{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6048ea0a-229a-42b4-830d-dd145c79d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00a793-1ae8-47e9-89f9-8052b23110af",
   "metadata": {},
   "source": [
    "## Random Forest Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ca4bc-d95e-414e-ac00-0fe6cb39266e",
   "metadata": {},
   "source": [
    "### Baseline Random Forest Model\n",
    "This is run on the cleaned/normalized data as well as sklearn default parameters. This gives us an idea of how this model may perform and potential hyperparameters to focus on during fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffbd9521-e0cd-4b70-a350-eacf4a27ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load data\n",
    "df_norm = pd.read_csv(\"../../data/processed/winequality-red-normalized.csv\")\n",
    "\n",
    "# split into features and target\n",
    "X_norm = df_norm.drop(columns=['quality'])\n",
    "y_norm = df_norm['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_norm, y_norm, test_size=0.2, random_state=42, stratify=y_norm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c11613d0-4b04-48c3-800a-1fc1a714d5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# fit baseline random forest\n",
    "rf_baseline = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "094cf60a-d2eb-4785-a875-c380fb6ab78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.684375\n",
      "F1 Score: 0.40597237221330523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "y_pred = rf_baseline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "088394d6-b29a-4895-af5f-92ab8793b7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.725352</td>\n",
       "      <td>0.757353</td>\n",
       "      <td>0.741007</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.684375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.432221</td>\n",
       "      <td>0.391677</td>\n",
       "      <td>0.405972</td>\n",
       "      <td>320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.661014</td>\n",
       "      <td>0.684375</td>\n",
       "      <td>0.669218</td>\n",
       "      <td>320.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "3              0.000000  0.000000  0.000000    2.000000\n",
       "4              0.000000  0.000000  0.000000   11.000000\n",
       "5              0.725352  0.757353  0.741007  136.000000\n",
       "6              0.643836  0.734375  0.686131  128.000000\n",
       "7              0.724138  0.525000  0.608696   40.000000\n",
       "8              0.500000  0.333333  0.400000    3.000000\n",
       "accuracy       0.684375  0.684375  0.684375    0.684375\n",
       "macro avg      0.432221  0.391677  0.405972  320.000000\n",
       "weighted avg   0.661014  0.684375  0.669218  320.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "df_report = pd.DataFrame(report_dict).transpose()\n",
    "df_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4d918-dff7-4457-a211-58af2cea0646",
   "metadata": {},
   "source": [
    "The random forest baseline model performs well on the most common wine qualities (5 and 6), achieving F1 scores of above 0.66, meaning that it's doing a pretty good job at correctly identifying the class while balancing false positives and false negatives. It struggles more with the minority classes (3, 4, and 8) due to the class imbalance present. The overall accuracy of 68.4% is pretty strong as a baseline for this dataset, but further fine-tuning is needed to improve performance further. However, the overall macro F1 score of 0.40 indicates that the model is again, performing poorly across all classes, indicating issues with minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f051ff3-cc71-4f91-a04a-9b69ee9e9657",
   "metadata": {},
   "source": [
    "### Improving the baseline model\n",
    "Next, we will perform Grid Search Cross Validation on each of the three datasets (our original, PCA, and interaction term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b227529-1ecf-4926-a7cd-9ee0b3b9639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5ac01f-7d86-4da0-8274-68c9881b7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"normalized\": pd.read_csv(\"../../data/processed/winequality-red-normalized.csv\"),\n",
    "    \"pca\": pd.read_csv(\"../../data/processed/winequality-red-pca.csv\"),\n",
    "    \"interactions\": pd.read_csv(\"../../data/processed/winequality-red-interactions.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "451b4e02-f506-48c6-a440-f21843ae1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150, 200],\n",
    "    \"max_depth\": [None, 15, 25, 50],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d52c8c75-58e6-446d-b2c1-621b920a9396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "normalized dataset\n",
      "Best parameters: {'class_weight': None, 'max_depth': 15, 'n_estimators': 50}\n",
      "CV Macro F1: 0.3359 (+/- 0.0208)\n",
      "Test Accuracy: 0.6594\n",
      "Test Macro F1: 0.3923\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.71      0.74      0.73       136\n",
      "           6       0.62      0.69      0.65       128\n",
      "           7       0.64      0.53      0.58        40\n",
      "           8       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.66       320\n",
      "   macro avg       0.41      0.38      0.39       320\n",
      "weighted avg       0.63      0.66      0.65       320\n",
      "\n",
      "\n",
      "pca dataset\n",
      "Best parameters: {'class_weight': None, 'max_depth': 15, 'n_estimators': 50}\n",
      "CV Macro F1: 0.3625 (+/- 0.0693)\n",
      "Test Accuracy: 0.6562\n",
      "Test Macro F1: 0.3880\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.69      0.76      0.73       136\n",
      "           6       0.62      0.68      0.65       128\n",
      "           7       0.72      0.45      0.55        40\n",
      "           8       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.66       320\n",
      "   macro avg       0.42      0.37      0.39       320\n",
      "weighted avg       0.64      0.66      0.64       320\n",
      "\n",
      "\n",
      "interactions dataset\n",
      "Best parameters: {'class_weight': 'balanced', 'max_depth': 15, 'n_estimators': 100}\n",
      "CV Macro F1: 0.3477 (+/- 0.0491)\n",
      "Test Accuracy: 0.6844\n",
      "Test Macro F1: 0.4018\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.73      0.78      0.75       136\n",
      "           6       0.64      0.72      0.68       128\n",
      "           7       0.69      0.50      0.58        40\n",
      "           8       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.68       320\n",
      "   macro avg       0.43      0.39      0.40       320\n",
      "weighted avg       0.66      0.68      0.67       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_table = []\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name} dataset\")\n",
    "\n",
    "    # split into X and y\n",
    "    X = df.drop(columns=[\"quality\"])\n",
    "    y = df[\"quality\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # grid search\n",
    "    grid = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_grid,\n",
    "        scoring=\"f1_macro\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid.best_params_\n",
    "    best_cv_score = grid.best_score_\n",
    "    cv_std = grid.cv_results_['std_test_score'][grid.best_index_]\n",
    "\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(f\"CV Macro F1: {best_cv_score:.4f} (+/- {cv_std:.4f})\")\n",
    "\n",
    "    # train best\n",
    "    best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # metrics\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    test_macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Test Macro F1: {test_macro_f1:.4f}\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    # store results in table\n",
    "    results_table.append({\n",
    "        \"Dataset\": name,\n",
    "        \"CV Macro F1 (mean)\": round(best_cv_score, 4),\n",
    "        \"CV Macro F1 (std)\": round(cv_std, 4),\n",
    "        \"Test Accuracy\": round(test_acc, 4),\n",
    "        \"Test Macro F1\": round(test_macro_f1, 4)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "215aad7d-f1ea-461c-ae3a-0987159bbca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>CV Macro F1 (mean)</th>\n",
       "      <th>CV Macro F1 (std)</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normalized</td>\n",
       "      <td>0.3359</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.3923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pca</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.3880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interactions</td>\n",
       "      <td>0.3477</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.6844</td>\n",
       "      <td>0.4018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset  CV Macro F1 (mean)  CV Macro F1 (std)  Test Accuracy  \\\n",
       "0    normalized              0.3359             0.0208         0.6594   \n",
       "1           pca              0.3625             0.0693         0.6562   \n",
       "2  interactions              0.3477             0.0491         0.6844   \n",
       "\n",
       "   Test Macro F1  \n",
       "0         0.3923  \n",
       "1         0.3880  \n",
       "2         0.4018  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9378d0-7788-440a-a759-a29d8325cbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
