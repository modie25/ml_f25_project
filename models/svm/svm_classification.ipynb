{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classification\n",
    "\n",
    "This notebook implements Support Vector Machine (SVM) classification for wine quality prediction using three preprocessed datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Support Vector Machine Method\n",
    "\n",
    "Support Vector Machine (SVM) is a powerful classification method that seeks to find an optimal separating hyperplane by maximizing the margin between different classes. Given a training data set $\\mathcal{D} = \\{(\\boldsymbol{x}_i, y_i)\\}_{i=1}^N$, where $\\boldsymbol{x}_i \\in \\mathcal{R}^d$ and $y_i \\in \\{-1, +1\\}$ for binary classification, we seek a linear model classifier in the form:\n",
    "\n",
    "$$y(\\boldsymbol{x}) = \\boldsymbol{w}^T \\boldsymbol{\\phi}(\\boldsymbol{x}) + b$$\n",
    "\n",
    "where $\\boldsymbol{\\phi}(\\boldsymbol{x})$ denotes a fixed feature-space transformation, $\\boldsymbol{w}$ is the weight vector, and $b$ is the bias parameter. For a binary linearly separable data set, there exists at least one choice of $\\boldsymbol{w}$ and $b$ that satisfies:\n",
    "\n",
    "$$y_i(\\boldsymbol{w}^T \\boldsymbol{\\phi}(\\boldsymbol{x}_i) + b) > 0, \\quad i = 1, \\ldots, N$$\n",
    "\n",
    "The margin of a hyperplane is defined as the geometric distance of the closest point in the data set to the hyperplane, given by:\n",
    "\n",
    "$$\\gamma = \\min_i \\frac{y_i(\\boldsymbol{w}^T \\boldsymbol{\\phi}(\\boldsymbol{x}_i) + b)}{\\|\\boldsymbol{w}\\|}$$\n",
    "\n",
    "Since rescaling of $\\boldsymbol{w}$ and $b$ does not change the hyperplane, we can use this freedom to produce constraints such that the margin becomes $\\gamma = 1/\\|\\boldsymbol{w}\\|$. The maximum margin solution is found by solving the optimization problem:\n",
    "\n",
    "$$\\arg \\min_{\\boldsymbol{w}, b} \\frac{1}{2}\\|\\boldsymbol{w}\\|^2$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$y_i(\\boldsymbol{w}^T \\boldsymbol{\\phi}(\\boldsymbol{x}_i) + b) \\geq 1, \\quad i = 1, 2, \\ldots, N$$\n",
    "\n",
    "This is a quadratic programming problem. For non-linearly separable data sets, we extend this to the soft margin formulation by introducing slack variables $\\xi_i \\geq 0$:\n",
    "\n",
    "$$\\arg \\min_{\\boldsymbol{w}, b, \\boldsymbol{\\xi}} \\frac{1}{2}\\|\\boldsymbol{w}\\|^2 + C \\sum_{i=1}^N \\xi_i$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$y_i(\\boldsymbol{w}^T \\boldsymbol{\\phi}(\\boldsymbol{x}_i) + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0, \\quad i = 1, 2, \\ldots, N$$\n",
    "\n",
    "where $C > 0$ is a regularization parameter that controls the trade-off between maximizing the margin and minimizing classification errors.\n",
    "\n",
    "**Implementation:** We implement SVM using scikit-learn's `SVC` class with a radial basis function (RBF) kernel, defined as $k(\\boldsymbol{x}, \\boldsymbol{x}') = \\exp(-\\gamma \\|\\boldsymbol{x} - \\boldsymbol{x}'\\|^2)$, which allows for non-linear decision boundaries. For our multi-class wine quality classification problem (6 classes: quality scores 3-8), we use the one-versus-rest (OvR) strategy, training one binary classifier per class.\n",
    "\n",
    "We evaluate SVM performance on three preprocessed datasets: (1) the normalized baseline dataset (11 features), (2) the dataset with interaction features (18 features), and (3) the PCA-transformed dataset (9 principal components retaining 95% variance). For each dataset, we perform an 80-20 train-test split using stratified sampling to preserve class distribution.\n",
    "\n",
    "Hyperparameter tuning is performed using grid search with 5-fold cross-validation. For each parameter combination, the model is trained on 4 folds and validated on the remaining fold, repeating this process 5 times. The combination yielding the highest average cross-validation macro F1-score is selected as optimal.\n",
    "Grid search optimizes for macro F1-score rather than accuracy to address class imbalance in the dataset. Macro F1-score gives equal weight to all classes, ensuring the model performs well across both majority and minority classes, rather than optimizing primarily for classes 5 and 6 which contain most of the data.\n",
    "The regularization parameter $C$ is evaluated over $\\{0.1, 1, 10, 100\\}$, controlling the trade-off between maximizing the margin and minimizing classification errors. Larger values (e.g., 100) penalize misclassifications more heavily, resulting in a smaller margin but fewer training errors, while smaller values (e.g., 0.1) prioritize a larger margin for better generalization.\n",
    "\n",
    "The kernel parameter $\\gamma$ is evaluated over $\\{\\text{'scale'}, \\text{'auto'}, 0.001, 0.01, 0.1, 1\\}$, determining the influence of training examples on the decision boundary. When $\\gamma = \\text{'scale'}$, it is computed as $\\gamma = 1/(n_{\\text{features}} \\times \\text{var}(X))$, adapting to both dimensionality and data scale. When $\\gamma = \\text{'auto'}$, it is set to $\\gamma = 1/n_{\\text{features}}$, considering only the number of features. Numeric values are fixed, with larger values (e.g., 1) creating more complex, localized boundaries and smaller values (e.g., 0.001) producing smoother, more generalized boundaries.\n",
    "\n",
    "This parameter grid results in $4 \\times 6 = 24$ unique combinations evaluated per dataset. The best model from cross-validation is evaluated on the held-out test set. Performance is assessed using accuracy, macro F1-score, precision, recall, and confusion matrices, with both test set and cross-validation results (mean macro F1-score \u00b1 standard deviation) reported to assess model stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:29:13.054474Z",
     "iopub.status.busy": "2025-12-08T00:29:13.053775Z",
     "iopub.status.idle": "2025-12-08T00:29:14.555929Z",
     "shell.execute_reply": "2025-12-08T00:29:14.556134Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Preprocessed Datasets\n",
    "\n",
    "We load the three preprocessed datasets prepared in the EDA phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:29:14.559737Z",
     "iopub.status.busy": "2025-12-08T00:29:14.559328Z",
     "iopub.status.idle": "2025-12-08T00:29:14.578397Z",
     "shell.execute_reply": "2025-12-08T00:29:14.578598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes:\n",
      "Normalized: (1599, 12)\n",
      "Interactions: (1599, 19)\n",
      "PCA: (1599, 10)\n",
      "\n",
      "Quality distribution: quality\n",
      "3     10\n",
      "4     53\n",
      "5    681\n",
      "6    638\n",
      "7    199\n",
      "8     18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the three preprocessed datasets\n",
    "df_normalized = pd.read_csv('../../data/processed/winequality-red-normalized.csv')\n",
    "df_interactions = pd.read_csv('../../data/processed/winequality-red-interactions.csv')\n",
    "df_pca = pd.read_csv('../../data/processed/winequality-red-pca.csv')\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"Normalized: {df_normalized.shape}\")\n",
    "print(f\"Interactions: {df_interactions.shape}\")\n",
    "print(f\"PCA: {df_pca.shape}\")\n",
    "\n",
    "# Separate features and target for each dataset\n",
    "X_norm = df_normalized.drop('quality', axis=1)\n",
    "y_norm = df_normalized['quality']\n",
    "\n",
    "X_inter = df_interactions.drop('quality', axis=1)\n",
    "y_inter = df_interactions['quality']\n",
    "\n",
    "X_pca = df_pca.drop('quality', axis=1)\n",
    "y_pca = df_pca['quality']\n",
    "\n",
    "print(f\"\\nQuality distribution: {y_norm.value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "\n",
    "We train SVM models on each dataset using RBF kernel with hyperparameter tuning via grid search and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:29:14.583440Z",
     "iopub.status.busy": "2025-12-08T00:29:14.583112Z",
     "iopub.status.idle": "2025-12-08T00:29:22.818719Z",
     "shell.execute_reply": "2025-12-08T00:29:22.818975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training SVM on Normalized dataset\n",
      "============================================================\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Best parameters: {'C': 10, 'gamma': 0.1}\n",
      "Test Accuracy: 0.6219\n",
      "F1-Score (macro): 0.3157\n",
      "CV Macro F1: 0.3634 (+/- 0.1216)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.68      0.70      0.69       136\n",
      "           6       0.60      0.63      0.62       128\n",
      "           7       0.61      0.57      0.59        40\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62       320\n",
      "   macro avg       0.31      0.32      0.32       320\n",
      "weighted avg       0.60      0.62      0.61       320\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training SVM on Interactions dataset\n",
      "============================================================\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Best parameters: {'C': 100, 'gamma': 0.1}\n",
      "Test Accuracy: 0.6156\n",
      "F1-Score (macro): 0.3834\n",
      "CV Macro F1: 0.3491 (+/- 0.1626)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.14      0.09      0.11        11\n",
      "           5       0.65      0.73      0.69       136\n",
      "           6       0.62      0.58      0.60       128\n",
      "           7       0.59      0.55      0.57        40\n",
      "           8       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.62       320\n",
      "   macro avg       0.39      0.38      0.38       320\n",
      "weighted avg       0.61      0.62      0.61       320\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training SVM on PCA dataset\n",
      "============================================================\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Best parameters: {'C': 100, 'gamma': 'auto'}\n",
      "Test Accuracy: 0.6375\n",
      "F1-Score (macro): 0.4100\n",
      "CV Macro F1: 0.3644 (+/- 0.1624)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.69      0.73      0.71       136\n",
      "           6       0.64      0.62      0.63       128\n",
      "           7       0.65      0.60      0.62        40\n",
      "           8       0.40      0.67      0.50         3\n",
      "\n",
      "    accuracy                           0.64       320\n",
      "   macro avg       0.40      0.44      0.41       320\n",
      "weighted avg       0.63      0.64      0.63       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate on each dataset\n",
    "datasets = {\n",
    "    'Normalized': (X_norm, y_norm),\n",
    "    'Interactions': (X_inter, y_inter),\n",
    "    'PCA': (X_pca, y_pca)\n",
    "}\n",
    "\n",
    "for name, (X, y) in datasets.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training SVM on {name} dataset\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Grid search with cross-validation\n",
    "    svm = SVC(kernel='rbf', random_state=42)\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = best_svm.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(best_svm, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': best_svm,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-Score (macro): {f1:.4f}\")\n",
    "    print(f\"CV Macro F1: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "    print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Comparison\n",
    "\n",
    "We compare the performance across the three datasets using accuracy, F1-score, and confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:29:22.823224Z",
     "iopub.status.busy": "2025-12-08T00:29:22.822861Z",
     "iopub.status.idle": "2025-12-08T00:29:22.830225Z",
     "shell.execute_reply": "2025-12-08T00:29:22.830434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Comparison Across Datasets:\n",
      "================================================================================\n",
      "     Dataset  Accuracy  Macro F1-Score  CV Macro F1 (mean)  CV Macro F1 (std)  Best C Best gamma\n",
      "  Normalized  0.621875        0.315686            0.363394           0.060799      10        0.1\n",
      "Interactions  0.615625        0.383358            0.349053           0.081300     100        0.1\n",
      "         PCA  0.637500        0.410000            0.364441           0.081179     100       auto\n",
      "================================================================================\n",
      "\n",
      "Results saved to ../../results/svm_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Dataset': list(results.keys()),\n",
    "    'Accuracy': [results[k]['accuracy'] for k in results.keys()],\n",
    "    'Macro F1-Score': [results[k]['f1_score'] for k in results.keys()],\n",
    "    'CV Macro F1 (mean)': [results[k]['cv_mean'] for k in results.keys()],\n",
    "    'CV Macro F1 (std)': [results[k]['cv_std'] for k in results.keys()],\n",
    "    'Best C': [results[k]['best_params']['C'] for k in results.keys()],\n",
    "    'Best gamma': [results[k]['best_params']['gamma'] for k in results.keys()]\n",
    "})\n",
    "\n",
    "print(\"Performance Comparison Across Datasets:\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Save results\n",
    "comparison_df.to_csv('../../results/svm_comparison.csv', index=False)\n",
    "print(\"\\nResults saved to ../../results/svm_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Results\n",
    "\n",
    "We visualize the confusion matrices for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:29:22.838558Z",
     "iopub.status.busy": "2025-12-08T00:29:22.838246Z",
     "iopub.status.idle": "2025-12-08T00:29:23.476866Z",
     "shell.execute_reply": "2025-12-08T00:29:23.477099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrices saved to ../../figures/svm_confusion_matrices.png\n"
     ]
    }
   ],
   "source": [
    "# Normalized Confusion matrices (percentages)import osos.makedirs('../../figures', exist_ok=True)fig, axes = plt.subplots(1, 3, figsize=(18, 5))quality_labels = sorted(y_norm.unique())for idx, (name, result) in enumerate(results.items()):    cm = result['confusion_matrix']    # Normalize confusion matrix by row (each row sums to 1.0)    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]        sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', ax=axes[idx],                xticklabels=quality_labels, yticklabels=quality_labels,                vmin=0, vmax=1, cbar_kws={'shrink': 0.8})    axes[idx].set_xlabel('Predicted Quality', fontsize=11, fontweight='bold')    axes[idx].set_ylabel('True Quality', fontsize=11, fontweight='bold')    axes[idx].set_title(f'Confusion Matrix: {name}', fontsize=12, fontweight='bold')plt.tight_layout()plt.savefig('../../figures/svm_confusion_matrices.png', dpi=300, bbox_inches='tight')plt.close()print(\"Normalized confusion matrices saved to ../../figures/svm_confusion_matrices.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Results and Analysis\n",
    "\n",
    "## 4.1 Support Vector Machine Results\n",
    "\n",
    "We evaluate SVM performance across three preprocessed datasets to assess the impact of different feature representations on classification accuracy. The performance metrics for each dataset are summarized in Table 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation results show consistent performance across folds, with standard deviations below 3.5% for all datasets, indicating stable model behavior. The optimal hyperparameters vary across datasets: the normalized dataset benefits from moderate regularization ($C=10$), while PCA requires stronger regularization ($C=100$), and interactions perform best with minimal regularization ($C=1$). For the $\\gamma$ parameter, both normalized and PCA datasets use $\\gamma=1$, while interactions uses $\\gamma=\\text{'auto'}$, which automatically sets $\\gamma = 1/(n_{\\text{features}} \\times \\text{var}(X))$ based on the number of features and variance of the data. A detailed analysis of class-wise performance, including confusion matrices, is provided in the appendix (Figure A1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Additional SVM Visualizations\n",
    "\n",
    "### A1. Confusion Matrices for SVM\n",
    "\n",
    "The confusion matrices reveal consistent patterns across all three datasets. The model performs well on the majority classes (quality 5 and 6), which together represent approximately 82% of the dataset. However, the model struggles significantly with minority classes (quality 3, 4, and 8), achieving near-zero precision and recall for these classes. This reflects the class imbalance inherent in the dataset, where quality scores 3, 4, and 8 represent only 0.6%, 3.3%, and 1.1% of samples, respectively. The model's conservative predictions for class 7 (high precision but low recall) further highlight the challenge of distinguishing between adjacent quality levels.\n",
    "\n",
    "The normalized and PCA datasets show nearly identical confusion patterns, with both correctly classifying approximately 100-101 samples of quality 5 and 97-99 samples of quality 6. The interactions dataset exhibits slightly more confusion between classes 5 and 6, with 42 misclassifications of true quality 6 as quality 5, compared to 27-28 in the other datasets. This increased confusion, combined with lower overall accuracy, suggests that the interaction features do not provide additional discriminative power for this classification task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}