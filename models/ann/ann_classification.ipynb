{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cb8b7d6-76e2-4b09-af5b-64d276ff1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2222e87-8df3-46c0-a84f-bad9feae3578",
   "metadata": {},
   "source": [
    "Inspired by biological neural networks in animal brains, Artificial Neural Networks (ANN) are the result of decades computational model adaptations and discoveries to create a powerful computing system that mimics \"learning\" through example without specified rules. The invention of the perceptron model (1957, B.Wildrow and M.Hoff), a method involving learnable weights and thresholds, lead to key theoretical basis integral to ANNs. Because single layer perceptrons were unable to handle the \"exclusive or\" problem by effectively predicting the outputs of non-linearly seperable datasets. The introduction of backpropagation for training multiple-layered perceptrons allowed for networks to learn nonlinear decision boundaries by stacking multiple layers of neurons, or nodes.\n",
    "\n",
    "ANNs are comprised of at least three layers of nodes: an input layer that recieves the raw features, at least one \"hidden\" layer that performs intermediate transformation, and an output layer that applies the activation function to produce a prediction.\n",
    "\n",
    "\n",
    "Hidden nodes compute \n",
    "\n",
    "$\\sum{\\ x_iw_{ij}={w^T}_jx}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38fa8564-5fc3-4197-8ef2-04b54d30b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv('../../data/processed/winequality-red-normalized.csv')\n",
    "#df_normalized = pd.read_csv('../../data/processed/winequality-red-normalized.csv')\n",
    "#df_interactions = pd.read_csv('../../data/processed/winequality-red-interactions.csv')\n",
    "#df_pca = pd.read_csv('../../data/processed/winequality-red-pca.csv')\n",
    "\n",
    "df=pd.read_csv('winequality-red-normalized.csv')\n",
    "df_normalized = pd.read_csv('winequality-red-normalized.csv')\n",
    "df_interactions = pd.read_csv('winequality-red-normalized.csv')\n",
    "df_pca = pd.read_csv('winequality-red-normalized.csv')\n",
    "\n",
    "X_norm = df_normalized.drop('quality', axis=1)\n",
    "y_norm = df_normalized['quality']\n",
    "\n",
    "X_inter = df_interactions.drop('quality', axis=1)\n",
    "y_inter = df_interactions['quality']\n",
    "\n",
    "X_pca = df_pca.drop('quality', axis=1)\n",
    "y_pca = df_pca['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01af1f22-057f-4160-bb7a-627095b3cd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Normalized best params: {'mlp__activation': 'tanh', 'mlp__alpha': 1e-05, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.0005, 'mlp__solver': 'adam'}\n",
      "Normalized CV macro F1: 0.28058829536122276\n",
      "Normalized Test Accuracy: 0.5625\n",
      "Normalized Test Macro F1: 0.256403017490465\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Interactions best params: {'mlp__activation': 'tanh', 'mlp__alpha': 1e-05, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.0005, 'mlp__solver': 'adam'}\n",
      "Interactions CV macro F1: 0.28058829536122276\n",
      "Interactions Test Accuracy: 0.5625\n",
      "Interactions Test Macro F1: 0.256403017490465\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "PCA best params: {'mlp__activation': 'tanh', 'mlp__alpha': 1e-05, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.0005, 'mlp__solver': 'adam'}\n",
      "PCA CV macro F1: 0.28058829536122276\n",
      "PCA Test Accuracy: 0.5625\n",
      "PCA Test Macro F1: 0.256403017490465\n"
     ]
    }
   ],
   "source": [
    "# # Common CV setup\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# param_grid = {\n",
    "#     'mlp__hidden_layer_sizes': [(64,), (64, 32), (128, 64)],\n",
    "#     'mlp__activation': ['relu', 'tanh'],\n",
    "#     'mlp__alpha': [1e-5, 1e-4, 1e-3],\n",
    "#     'mlp__learning_rate_init': [5e-4, 1e-3, 2e-3],\n",
    "#     'mlp__solver': ['adam']\n",
    "# }\n",
    "\n",
    "# def run_pipeline(X, y, label):\n",
    "#     # consistent split\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.2, stratify=y, random_state=42\n",
    "#     )\n",
    "\n",
    "#     pipe = Pipeline([\n",
    "#         ('mlp', MLPClassifier(max_iter=600,\n",
    "#                               early_stopping=True,\n",
    "#                               n_iter_no_change=20,\n",
    "#                               random_state=42))\n",
    "#     ])\n",
    "\n",
    "#     grid = GridSearchCV(pipe, param_grid, scoring='f1_macro',\n",
    "#                         cv=cv, n_jobs=-1, verbose=1, refit=True)\n",
    "#     grid.fit(X_train, y_train)\n",
    "\n",
    "#     print(f\"{label} best params:\", grid.best_params_)\n",
    "#     print(f\"{label} CV macro F1:\", grid.best_score_)\n",
    "\n",
    "#     y_pred = grid.predict(X_test)\n",
    "#     print(f\"{label} Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "#     print(f\"{label} Test Macro F1:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# # Run for each dataset version\n",
    "# run_pipeline(X_norm, y_norm, \"Normalized\")\n",
    "# run_pipeline(X_inter, y_inter, \"Interactions\")\n",
    "# run_pipeline(X_pca, y_pca, \"PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3662ed80-d799-4c32-a21a-f1abd7f15732",
   "metadata": {},
   "source": [
    "things to do:\n",
    "change the learning rates\n",
    "describe the activation, choices of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf309292-10f4-466d-a7bc-627017a4d657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training ANN on Normalized dataset\n",
      "============================================================\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "\n",
      "Best parameters: {'activation': 'tanh', 'alpha': 1e-05, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.002, 'solver': 'adam'}\n",
      "Test Accuracy: 0.5969\n",
      "Macro F1-Score: 0.2925\n",
      "CV Macro F1: 0.2972 (+/- 0.1187)\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1  1  0  0]\n",
      " [ 0  0 10  1  0  0]\n",
      " [ 0  0 94 41  1  0]\n",
      " [ 0  0 42 81  5  0]\n",
      " [ 0  0  1 23 16  0]\n",
      " [ 0  0  0  2  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3     0.0000    0.0000    0.0000         2\n",
      "           4     0.0000    0.0000    0.0000        11\n",
      "           5     0.6351    0.6912    0.6620       136\n",
      "           6     0.5436    0.6328    0.5848       128\n",
      "           7     0.6957    0.4000    0.5079        40\n",
      "           8     0.0000    0.0000    0.0000         3\n",
      "\n",
      "    accuracy                         0.5969       320\n",
      "   macro avg     0.3124    0.2873    0.2925       320\n",
      "weighted avg     0.5743    0.5969    0.5788       320\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training ANN on Interactions dataset\n",
      "============================================================\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "\n",
      "Best parameters: {'activation': 'tanh', 'alpha': 1e-05, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.002, 'solver': 'adam'}\n",
      "Test Accuracy: 0.5969\n",
      "Macro F1-Score: 0.2925\n",
      "CV Macro F1: 0.2972 (+/- 0.1187)\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1  1  0  0]\n",
      " [ 0  0 10  1  0  0]\n",
      " [ 0  0 94 41  1  0]\n",
      " [ 0  0 42 81  5  0]\n",
      " [ 0  0  1 23 16  0]\n",
      " [ 0  0  0  2  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3     0.0000    0.0000    0.0000         2\n",
      "           4     0.0000    0.0000    0.0000        11\n",
      "           5     0.6351    0.6912    0.6620       136\n",
      "           6     0.5436    0.6328    0.5848       128\n",
      "           7     0.6957    0.4000    0.5079        40\n",
      "           8     0.0000    0.0000    0.0000         3\n",
      "\n",
      "    accuracy                         0.5969       320\n",
      "   macro avg     0.3124    0.2873    0.2925       320\n",
      "weighted avg     0.5743    0.5969    0.5788       320\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training ANN on PCA dataset\n",
      "============================================================\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "\n",
      "Best parameters: {'activation': 'tanh', 'alpha': 1e-05, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.002, 'solver': 'adam'}\n",
      "Test Accuracy: 0.5969\n",
      "Macro F1-Score: 0.2925\n",
      "CV Macro F1: 0.2972 (+/- 0.1187)\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  1  1  0  0]\n",
      " [ 0  0 10  1  0  0]\n",
      " [ 0  0 94 41  1  0]\n",
      " [ 0  0 42 81  5  0]\n",
      " [ 0  0  1 23 16  0]\n",
      " [ 0  0  0  2  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3     0.0000    0.0000    0.0000         2\n",
      "           4     0.0000    0.0000    0.0000        11\n",
      "           5     0.6351    0.6912    0.6620       136\n",
      "           6     0.5436    0.6328    0.5848       128\n",
      "           7     0.6957    0.4000    0.5079        40\n",
      "           8     0.0000    0.0000    0.0000         3\n",
      "\n",
      "    accuracy                         0.5969       320\n",
      "   macro avg     0.3124    0.2873    0.2925       320\n",
      "weighted avg     0.5743    0.5969    0.5788       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"Normalized\": (X_norm, y_norm),\n",
    "    \"Interactions\": (X_inter, y_inter),\n",
    "    \"PCA\": (X_pca, y_pca)\n",
    "}\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(64,), (64, 32), (128, 64)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3],\n",
    "    \"learning_rate_init\": [5e-4, 1e-3, 2e-3],\n",
    "    \"solver\": [\"adam\"]\n",
    "}\n",
    "results = {}\n",
    "\n",
    "for name, (X, y) in datasets.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training ANN on {name} dataset\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Grid search\n",
    "    ann = MLPClassifier(max_iter=600, early_stopping=True, n_iter_no_change=20, random_state=42)\n",
    "    grid = GridSearchCV(\n",
    "        ann,\n",
    "        param_grid,\n",
    "        cv=5, \n",
    "        scoring=\"f1_macro\", \n",
    "        n_jobs=-1, \n",
    "        verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_ann = grid.best_estimator_\n",
    "    y_pred = best_ann.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1m = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    cv_scores = cross_val_score(best_ann, X_train, y_train, cv=5, scoring=\"f1_macro\")\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_macro\": f1m,\n",
    "        \"cv_mean\": cv_scores.mean(),\n",
    "        \"cv_std\": cv_scores.std(),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred),\n",
    "        \"report\": classification_report(y_test, y_pred, digits=4,zero_division=0)\n",
    "    }\n",
    "    \n",
    "    # Print\n",
    "    print(f\"\\nBest parameters: {grid.best_params_}\")\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    print(f\"Macro F1-Score: {f1m:.4f}\")\n",
    "    print(f\"CV Macro F1: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "    print(\"\\nConfusion Matrix:\\n\", results[name][\"confusion_matrix\"])\n",
    "    print(\"\\nClassification Report:\\n\", results[name][\"report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed0b6bfa-f4b8-467a-9303-84cec960e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANN Results Summary ===\n",
      "                                                    best_params  accuracy  \\\n",
      "Normalized    {'activation': 'tanh', 'alpha': 1e-05, 'hidden...  0.596875   \n",
      "Interactions  {'activation': 'tanh', 'alpha': 1e-05, 'hidden...  0.596875   \n",
      "PCA           {'activation': 'tanh', 'alpha': 1e-05, 'hidden...  0.596875   \n",
      "\n",
      "              f1_macro   cv_mean    cv_std  \n",
      "Normalized    0.292458  0.297194  0.059325  \n",
      "Interactions  0.292458  0.297194  0.059325  \n",
      "PCA           0.292458  0.297194  0.059325  \n"
     ]
    }
   ],
   "source": [
    "# Convert results dict to DataFrame\n",
    "summary = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "# Select only the columns you want in the table\n",
    "summary_table = summary[[\n",
    "    'best_params',\n",
    "    'accuracy',\n",
    "    'f1_macro',\n",
    "    'cv_mean',\n",
    "    'cv_std'\n",
    "]]\n",
    "\n",
    "print(\"\\n=== ANN Results Summary ===\")\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c92624-2dc1-469a-991f-01a15063d8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4b2f0-f631-43dd-accd-c51ebafae005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
